{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial-12_RobustLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Robust LP with Polyhedron Cost Complexity"
      ],
      "metadata": {
        "id": "dBhFEfuE0JVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization Problem "
      ],
      "metadata": {
        "id": "5vQRWSOl3XAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "$\\begin{gather}\n",
        "\\quad \\text{minimize} \\quad & \\sup_{c \\in \\mathcal{C}} c^Tx \\\\\n",
        "\\quad \\text{subject to} \\quad & Ax \\geq b \\\\\n",
        "\\end{gather}$\n",
        "<br> <br>\n",
        "$\\text{where } \\mathcal{C} = \\{ c \\ | \\ Fc \\leq g \\}$"
      ],
      "metadata": {
        "id": "9EKCAvQC2oON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (a) Convexity of $f(x) = \\sup_{c \\in \\mathcal{C}} c^Tx$"
      ],
      "metadata": {
        "id": "zJ2TIrgF32dk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$f(x) := c_x^Tx$ $\\text{ such that }$ $c_x^Tx \\geq c^Tx \\ \\forall \\ c \\in \\mathcal{C}$\n",
        "\n",
        "<br>\n",
        "\n",
        "$\\text{For some }$ $\\theta \\in [0, 1], $\n",
        "\n",
        "$\\text{It can be inferred that }$ $f(\\theta x) = \\theta c_x^T x$ $\\text{ since }$ \n",
        "$\\ \\theta c_x^Tx \\geq \\theta c^Tx \\ \\forall \\ c \\in \\mathcal{C}$\n",
        "\n",
        "<br>\n",
        "\n",
        "$\\text{Suppose, }$ \n",
        "$f(\\theta x + (1 - \\theta)y) = c_\\theta^T (\\theta x + (1 - \\theta)y)$\n",
        "\n",
        "<br>\n",
        "\n",
        "$\\text{We need to prove Jensen's Inequality for Convexity }$\n",
        "\n",
        "$f(\\theta x + (1 - \\theta)y) \\ \\leq \\ \\theta f(x) + (1-\\theta)f(y) \\ \\forall \\ \\ \\theta \\in [0, 1]$\n",
        "\n",
        "$\\text{That is, }$ $c_\\theta^T (\\theta x + (1 - \\theta)y) \\ \\leq \\ \\theta c_x^Tx + (1-\\theta)c_y^Ty \\ \\forall \\ \\ \\theta \\in [0, 1]$\n",
        "\n",
        "<br>\n",
        "\n",
        "$\\text{Since }$ $c_x^Tx \\geq c_\\theta^Tx \\text{ and } c_y^Ty \\geq c_\\theta^Ty$,\n",
        "$\\text{ the above condition is satisfied and hence}$\n",
        "\n",
        "$\\mathbf{f(x) = \\sup_{c \\in \\mathcal{C}} c^Tx}$ $\\text{is Convex}$\n",
        "\n",
        "<br><br>"
      ],
      "metadata": {
        "id": "KCU0TKyy4ZRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (b) Getting $f(x)$"
      ],
      "metadata": {
        "id": "3WQg-EOf3YGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\n",
        "f(x) = \n",
        "\\left( \\begin{gather*} \n",
        "\\text{maximize} & c^Tx \\\\\n",
        "\\text{subject to} & Fc \\leq g \\\\\n",
        "\\end{gather*} \\right)\n",
        "$\n",
        "\n",
        "<br><br>\n",
        "\n",
        "$\n",
        "f(x) = \n",
        "\\left( \\begin{gather*} \n",
        "\\text{minimize} & -x^Tc \\\\\n",
        "\\text{subject to} & Fc - g \\leq 0 \\\\\n",
        "\\end{gather*} \\right)\n",
        "$\n",
        "\n",
        "<br><br>\n",
        "\n",
        "$\n",
        "\\text{Lagrangian}, \\ L(x, \\lambda_+) = -x^T c + \\lambda_+^T(Fc-g) = -g^T \\lambda_+ + (F^T \\lambda_+ - x)^T c \\quad \\quad \\leq -x^Tc \\\\\n",
        "\\text{Dual}, \\ g(\\lambda_+) = \\underset{x}{\\inf} L(x, \\lambda_+) = -g^T \\lambda_+ + \\underset{x}{\\inf} \\ (F^T \\lambda_+ - x)^T c \\\\\n",
        "g(\\lambda_+) \\ = \\ -g^T \\lambda_+ \\quad \\text{ if } \\quad (F^T \\lambda_+ - x)^T = 0 \\quad \\text{ and } \\quad \\lambda_+ \\geq 0 \\\\\n",
        "g(\\lambda_+) \\ = \\ -\\infty \\quad \\text{ otherwise } \\quad  \\text{(Ignored as we need to maximize } \\ L(x, \\lambda_+) \\text{)} \\\\\n",
        "$\n",
        "\n",
        "\n",
        "<br><br>\n",
        "\n",
        "$\n",
        "\\text{Therefore, } \\\\\n",
        "f'(x) = \n",
        "\\left( \\begin{gather*} \n",
        "\\text{maximize} & -g^T \\lambda_+ \\\\\n",
        "\\text{subject to} & F^T\\lambda_+ - x = 0 \\\\\n",
        "\\ & \\lambda_+ \\geq 0\n",
        "\\end{gather*} \\right)\n",
        "$\n",
        "\n",
        "$\n",
        "\\text{is the dual of the function } f(x) \\text{ and the optimal value is } f(x)\n",
        "$\n",
        "\n",
        "<br><br>\n",
        "\n",
        "$\n",
        "\\text{Therefore, } \\\\\n",
        "f(x) = \n",
        "\\left( \\begin{gather*} \n",
        "\\text{minimize} & g^T \\lambda_+ \\\\\n",
        "\\text{subject to} & F^T\\lambda_+ - x = 0 \\\\\n",
        "\\ & \\lambda_+ \\geq 0\n",
        "\\end{gather*} \\right)\n",
        "$\n",
        "\n",
        "<br><br>"
      ],
      "metadata": {
        "id": "nN4xgqqMDDLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (c) Formulating using $f(x)$"
      ],
      "metadata": {
        "id": "axG3rwvWC3I7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "$\n",
        "\\text{Our optimization problem is, } \\\\\n",
        "\\begin{gather}\n",
        "\\quad \\text{minimize} \\quad & f(x) \\\\\n",
        "\\quad \\text{subject to} \\quad & Ax \\geq b \\\\\n",
        "\\end{gather}$\n",
        "\n",
        "\n",
        "$\\text{where}$\n",
        "\n",
        "$\n",
        "f(x) = \n",
        "\\left( \\begin{gather*} \n",
        "\\text{minimize} & g^T \\lambda_+ \\\\\n",
        "\\text{subject to} & F^T\\lambda_+ - x = 0 \\\\\n",
        "\\ & \\lambda_+ \\geq 0\n",
        "\\end{gather*} \\right)\n",
        "$\n",
        "\n",
        "<br><br>\n",
        "\n",
        "$ \n",
        "\\text{Our optimization problem can be written as } \\\\\n",
        "\\left(\n",
        "\\begin{align}\n",
        "\\quad \\text{minimize} \\quad & \\quad \\quad g^T \\lambda_+ \\\\\n",
        "\\quad \\text{subject to} \\quad & F^T\\lambda_+ = \\ x, \\quad \\lambda_+ \\geq 0, \\quad Ax \\ \\geq \\ b \\\\\n",
        "\\end{align}\n",
        "\\right)\n",
        "$\n",
        "\n",
        "<br><br>"
      ],
      "metadata": {
        "id": "6JdQq-OCC8MN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (d) Solving the Robust LP"
      ],
      "metadata": {
        "id": "a5Lz9konEa-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Given"
      ],
      "metadata": {
        "id": "ouN2BChrXIiE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zWTwvnV50IsF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cvxpy as cp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(10)\n",
        "(m, n) = (30, 10)\n",
        "A = np.asmatrix(np.random.rand(m, n))\n",
        "b = np.asmatrix(np.random.rand(m, 1))\n",
        "c_nom = np.asmatrix(np.ones((n, 1)) + np.random.rand(n, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting the given constraints to $Fc \\ \\leq \\ g$"
      ],
      "metadata": {
        "id": "WkunCaHGKCRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "F = np.r_[\n",
        "          np.identity(n),  # For c <= 1.25c_nom\n",
        "          -np.identity(n),  # For -c <= -0.75c_nom\n",
        "          np.ones((1, n)) / n,  # For 1' @ c/n <= 1.1 (1' @ c_nom) / n\n",
        "          -np.ones((1, n)) / n  # For - 1' @ c/n <= -0.9 (1' @ c_nom) / n\n",
        "]\n",
        "\n",
        "g = np.r_[\n",
        "          1.25 * c_nom,\n",
        "          -0.75 * c_nom,\n",
        "          1.1 * np.ones(n) @ c_nom / n,\n",
        "          -0.9 * np.ones(n) @ c_nom / n\n",
        "]"
      ],
      "metadata": {
        "id": "KPGzoTDXKkbC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation"
      ],
      "metadata": {
        "id": "VzjK4d4pKRnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = cp.Variable((n, 1))\n",
        "lam_pos = cp.Variable((len(g), 1))\n",
        "\n",
        "objective = cp.Minimize(lam_pos.T @ g)\n",
        "constraints = [\n",
        "               A@x >= b,\n",
        "               F.T@lam_pos == x,\n",
        "               lam_pos >= 0\n",
        "]\n",
        "\n",
        "# Calculating x_nom Minimizing c_nom.T @ x with Ax >= b\n",
        "prob = cp.Problem(cp.Minimize(c_nom.T @ x), constraints[0:1])\n",
        "result_nom = prob.solve()\n",
        "x_nom = np.matrix(x.value)\n",
        "\n",
        "# Using Robust Constraints\n",
        "# f(x_rob) gives the worst case f(x)\n",
        "prob = cp.Problem(objective, constraints)\n",
        "result_rob = prob.solve()  \n",
        "x_rob = np.matrix(x.value)\n",
        "\n",
        "# For Nominal Case, we don't have the worst case f(x)\n",
        "# We use x_nom and calculate Worse case f(x) using the constraint on c\n",
        "c = cp.Variable((n, 1))\n",
        "objective = cp.Maximize(c.T @ x_nom)\n",
        "constraints = [\n",
        "               c <= 1.25 * c_nom,\n",
        "               0.75 * c_nom <= c,\n",
        "\n",
        "               c.T @ np.ones(n) / n <= 1.1 * np.mean(c_nom),\n",
        "               0.9 * np.mean(c_nom) <= c.T @ np.ones(n)\n",
        "]\n",
        "fx_nom_worst = cp.Problem(objective, constraints).solve()\n",
        "\n",
        "print(\"C-nom @ X: \")\n",
        "print(\"Without using Robust Constraints:\", np.sum(c_nom.T@x_nom))\n",
        "print(\"With using Robust Constraints:\", np.sum(c_nom.T@x_rob))\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"Worst Case f(x): \")\n",
        "print(\"Without using Robust Constraints:\", fx_nom_worst)\n",
        "print(\"Using the Robust Constraints:\", result_rob)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGQ3FLYOEak_",
        "outputId": "f3b2941e-3f37-4424-b3cb-c4326a68c6f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C-nom @ X: \n",
            "Without using Robust Constraints: 2.1092714620826003\n",
            "With using Robust Constraints: 2.5232088649062265\n",
            "\n",
            "Worst Case f(x): \n",
            "Without using Robust Constraints: 7.221562204118721\n",
            "Using the Robust Constraints: 3.16596105233182\n"
          ]
        }
      ]
    }
  ]
}